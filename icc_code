#!/usr/bin/env python
# coding: utf-8

# In[1]:


import json
import requests
from bs4 import BeautifulSoup

import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np


# In[2]:


cricket = []

with open('CricketTeams.txt', 'r') as file:
    
    for line in file:
        x = line.strip()
        url = 'http://www.espncricinfo.com/' + x.split(',')[0] + '/content/player/country.html?country=' + x.split(',')[1]
        print(url)
        
        html = requests.get(url)
        soup = BeautifulSoup(html.content, 'html.parser')
        
        #List of all the players including ODI, Test, T20
        rawPlayers = soup.find_all('td', class_="divider")
        
        #To get the list of unique players
        playerSet = set([])
        
        #Adding all players (ODI, Test, T20) to set
        for child in rawPlayers:
            playerSet.add(child.text)
        
        #Convert above set into list
        listPlayers = []
        for player in playerSet:
            listPlayers.append(player)
        
        team = []
        team.append(x.split(',')[0])
        team.append(listPlayers)
        #print(team)
        
        cricket.append(team)
        
    print(cricket)
    
with open('cricketTeams.json', 'w', encoding='utf-8') as file:
    json.dump(cricket, file, ensure_ascii=False, indent=2)

